{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "baseline_model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8RBu9DVrA4Y"
      },
      "source": [
        "# Exploratory analysis and Baseline modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqZ1_DnirA4o"
      },
      "source": [
        "## Summary\n",
        "\n",
        "The aim is to evaluate a **RandomForestRegressor** like a baseline model to estimate PM10.\n",
        "The following experiments are executed:\n",
        "  * **Experiment 1:** Use all available data to train and evaluate a model\n",
        "  * **Experiment 2:** Cross validation between stations\n",
        "  * **Experiment 3:** Compare models by sensor frequency\n",
        "  * **Experiment 4:** Compare models by satelite and frequency\n",
        "\n",
        "Also, other models are evaluated to compare against **RandomForestRegressor**:\n",
        "  * **KNRegressor**\n",
        "  * **MLPRegressor**\n",
        "  * **Linear SVR**\n",
        "  * **XGBRegressor**\n",
        "  \n",
        "  \n",
        "**Hypothesis**\n",
        "  1. RandomForestRegressor is a good baseline model\n",
        "  2. There is another model tath beats RandomForestRegressor\n",
        "  \n",
        "**Notes:**\n",
        "\n",
        "The dataset can be downloaded [here](https://drive.google.com/file/d/1W3JmH32LGJti1jg6Zhq-DQZds21NTREM/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-UwxQZFrA4q"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b80YoWsrA4r"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.core.display import HTML\n",
        "from matplotlib import rcParams\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
        "from typing import Any, Callable, Dict, Iterable, List\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "sns.set_theme()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6muOOY6rA4s"
      },
      "source": [
        "DATA_PATH = \"Tabla_Entrenamiento_MAIAC_MERRA_VIIRS_DEM_PM.csv\"\n",
        "TARGET_COL = \"PM10_valor\"\n",
        "FEATURES_COLS = [\n",
        "    'valor_AOD', 'DEM_asnm', 'VIIRS_night_lights', 'ALBEDO', 'BCCMASS', 'CLDHGH', \n",
        "    'CLDLOW', 'DMSSMASS', 'DUSMASS', 'OCSMASS', 'PBLH', 'PRECTOT','PS', 'RH', \n",
        "    'SO2SMASS', 'SO4SMASS', 'SPEED', 'SPEEDMAX','SSSMASS', 'T', 'U', 'USTAR', 'V'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2guhyhlrA4t"
      },
      "source": [
        "def summary(df: pd.DataFrame, n_sample: int=5) -> None:\n",
        "    \"\"\"\n",
        "    Show brief summary for a given Dataframe\n",
        "    Args:\n",
        "        df: Dataframe\n",
        "        n_sample: number of sample to display\n",
        "    \"\"\"\n",
        "    rows, columns = df.shape\n",
        "    display(HTML(f'<b>Nº Rows:</b> {rows}'))\n",
        "    display(HTML(f'<b>Nº Columns:</b> {columns}'))\n",
        "    display(HTML(f'<b>Sample:</b>'))\n",
        "    display(df.sample(n_sample))\n",
        "    \n",
        "\n",
        "def get_metrics(forecast: np.array, ground_truth: np.array) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate a set of metrics to measure the performance of the forecasting model\n",
        "\n",
        "    Args:\n",
        "        forecast: list of forecasted values\n",
        "        ground_truth: list of real values\n",
        "\n",
        "    Return:\n",
        "        Dictionary of the main forcasting metrics\n",
        "    \"\"\"\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs(ground_truth - forecast) / ground_truth) * 100  \n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(forecast, ground_truth)\n",
        "    # Root Mean Square Error\n",
        "    rmse = np.sqrt(mean_squared_error(forecast, ground_truth))\n",
        "    \n",
        "    # Explained variance score\n",
        "    ex_var = var_explained_variance_score(forecast, ground_truth)\n",
        "        \n",
        "    return {\n",
        "        \"mape\": mape,\n",
        "        \"mae\": mae,\n",
        "        \"rmse\": rmse,\n",
        "        \"ex_var\": ex_var,\n",
        "        \"n_sample\": len(ground_truth),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def search_best_model(X: np.array, y:np.array, model: Any, param_grid: Dict) -> Any:\n",
        "    \"\"\"\n",
        "    Randomized search on hyperparameters to get the best model\n",
        "    \n",
        "    Args:\n",
        "        X: dataset to train\n",
        "        y: targets to train\n",
        "        model: model instance to fit\n",
        "        param_grid: set of parameter to try \n",
        "    Return:\n",
        "        The best model fitted\n",
        "    \"\"\"\n",
        "    # Random search of parameters, using 3 fold cross validation, \n",
        "    # search across 100 different combinations, and use all available cores\n",
        "    rs = RandomizedSearchCV(\n",
        "                estimator=model,\n",
        "                param_distributions=param_grid,\n",
        "                n_iter = 100,\n",
        "                cv = 3,\n",
        "                verbose=2,\n",
        "                random_state=42,\n",
        "                n_jobs = -1\n",
        "            )\n",
        "    \n",
        "    rs.fit(X, y)\n",
        "    \n",
        "    return rs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgE7GtGrrA4u"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrXccbDSrA4v"
      },
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "summary(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuXAEKatrA4w"
      },
      "source": [
        "### Remove NA values from target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpqdxIOhrA4w"
      },
      "source": [
        "df.dropna(subset=[TARGET_COL], inplace=True)\n",
        "summary(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC9Eo1cUrA4x"
      },
      "source": [
        "### Remove NA values from feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5F84TVfrA4x"
      },
      "source": [
        "df.dropna(how='any', inplace=True)\n",
        "summary(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAzfLKlurA4y"
      },
      "source": [
        "### Get some distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waxAbDYWrA4y"
      },
      "source": [
        "#### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpYA0G6urA4z"
      },
      "source": [
        "df[FEATURES_COLS].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X__1fC-PrA40"
      },
      "source": [
        "#### Target (PM10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULT1Ed9erA41"
      },
      "source": [
        "df[TARGET_COL].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Uw6HAQrA42"
      },
      "source": [
        "sns.displot(df, x=TARGET_COL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNOloJAprA42"
      },
      "source": [
        "#### PM10 distribution by signal frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQDeMu_lrA43"
      },
      "source": [
        "df.groupby(\"AODnm\")[TARGET_COL].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPAKXjPZrA43"
      },
      "source": [
        "#### PM10 distribution by sensor and signal frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRtj7yUfrA44"
      },
      "source": [
        "df.groupby([\"AODnm\", \"Satelite\"])[TARGET_COL].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNxjSUJGrA44"
      },
      "source": [
        "#### PM10 distribution by monitoring station"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GmGr79OrA45"
      },
      "source": [
        "df.groupby([\"estacion_pm\"])[TARGET_COL].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loInlpVprA45"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUKP1l8lrA46"
      },
      "source": [
        "### Experiment 1:  Use all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxGZRgrZrA46"
      },
      "source": [
        "#### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capPEaXBrA46"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES_COLS], df[TARGET_COL], test_size = 0.20, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJgOIX0QrA47"
      },
      "source": [
        "#### Set param grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzuVqKirA47"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "rf_param_grid =  {\n",
        "    'n_estimators': n_estimators,\n",
        "    'max_features': max_features,\n",
        "    'max_depth': max_depth,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'min_samples_leaf': min_samples_leaf,\n",
        "    'bootstrap': bootstrap\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRII5GTIrA48"
      },
      "source": [
        "#### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSogEl1ZrA48"
      },
      "source": [
        "# Get best params\n",
        "display(HTML(f'<b>Randomized Search CV:</b>'))\n",
        "rf =  RandomForestRegressor()\n",
        "rf_random = search_best_model(X_train, y_train, rf, rf_param_grid)\n",
        "\n",
        "display(HTML(f'<b>Best params:</b>'))\n",
        "print(rf_random.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eetNV4girA49"
      },
      "source": [
        "# Training RF estimator with the best parameters to get feature importances\n",
        "rf.set_params(**rf_random.best_params_)\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UajyX7UBrA49"
      },
      "source": [
        "#### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32802-gxrA4_"
      },
      "source": [
        "# Training metrics\n",
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "print(get_metrics(np.array(y_train), rf.predict(X_train)))\n",
        "\n",
        "# Test metrics\n",
        "display(HTML(f'<b>Evaluation metrics:</b>'))\n",
        "print(get_metrics(np.array(y_test), rf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9TQZURXrA5A"
      },
      "source": [
        "#### Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImDJstNJrA5A"
      },
      "source": [
        "ax = sns.scatterplot(x=y_test, y=rf.predict(X_test))\n",
        "ax = ax.set(xlabel = \"PM10\", ylabel=\"Prediction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjWD6t_UrA5B"
      },
      "source": [
        "# Get feature importances\n",
        "feature_importances = list(zip(FEATURES_COLS, np.round(rf.feature_importances_, 2)))\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "_ = [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6319X9irA5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0WLuWrKrA5C"
      },
      "source": [
        "### Experiment 2: Cross validation between stations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPFBQidErA5D"
      },
      "source": [
        "station_metrics = {'train':{}, 'test':{}}\n",
        "for station in pd.unique(df.estacion_pm):\n",
        "    display(HTML(f'<b>Station to evaluate:</b> {station}'))\n",
        "    mask = df.estacion_pm == station\n",
        "    X_train = df[~mask][FEATURES_COLS]\n",
        "    y_train = df[~mask][TARGET_COL]\n",
        "    X_test = df[mask][FEATURES_COLS]\n",
        "    y_test = df[mask][TARGET_COL]\n",
        "    \n",
        "    \n",
        "    # Get best params\n",
        "    display(HTML(f'<b>Randomized Search CV:</b>'))\n",
        "    rf = search_best_model(X_train, y_train, RandomForestRegressor(), rf_param_grid)\n",
        "    \n",
        "    display(HTML(f'<b>Best params:</b>'))\n",
        "    print(rf.best_params_)\n",
        "    \n",
        "    # Training metrics\n",
        "    station_metrics['train'][station] = get_metrics(np.array(y_train), rf.predict(X_train))\n",
        "\n",
        "    # Test metrics\n",
        "    station_metrics['test'][station] = get_metrics(np.array(y_test), rf.predict(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYkHUgO8rA5F"
      },
      "source": [
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "display(pd.DataFrame(station_metrics['train']))\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "display(pd.DataFrame(station_metrics['test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K7pO-NWrA5F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXUin8PmrA5G"
      },
      "source": [
        "### Experiment 3: Compare models by sensor frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FkiC_pSrA5H"
      },
      "source": [
        "freq_metrics = {'train':{}, 'test':{}}\n",
        "for freq in pd.unique(df.AODnm):\n",
        "    display(HTML(f'<b>Frequency to evaluate:</b> {freq}'))\n",
        "    freq_df = df[df.AODnm == freq]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        freq_df[FEATURES_COLS],\n",
        "                                                        freq_df[TARGET_COL],\n",
        "                                                        test_size = 0.20,\n",
        "                                                        random_state = 42\n",
        "                                                    )\n",
        "    \n",
        "    # Get best params\n",
        "    display(HTML(f'<b>Randomized Search CV:</b>'))\n",
        "    rf = search_best_model(X_train, y_train, RandomForestRegressor(), rf_param_grid)\n",
        "    \n",
        "    display(HTML(f'<b>Best params:</b>'))\n",
        "    print(rf.best_params_)\n",
        "    \n",
        "    # Training metrics\n",
        "    freq_metrics['train'][freq] = get_metrics(np.array(y_train), rf.predict(X_train))\n",
        "\n",
        "    # Test metrics\n",
        "    freq_metrics['test'][freq] = get_metrics(np.array(y_test), rf.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktWO9v0hrA5I"
      },
      "source": [
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "display(pd.DataFrame(freq_metrics['train']))\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "display(pd.DataFrame(freq_metrics['test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id3R1Iw9rA5L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qv5i5zDrA5L"
      },
      "source": [
        "### Experiment 4: Compare models by satelite and frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTyEjXQRrA5M"
      },
      "source": [
        "sat_freq_metrics = {'train':{}, 'test':{}}\n",
        "for name, group  in df.groupby([\"AODnm\", \"Satelite\"]):\n",
        "    freq, sat = name\n",
        "    display(HTML(f'<b>Frequency to evaluate:</b> {freq}'))\n",
        "    display(HTML(f'<b>Satelite to evaluate:</b> {sat}'))\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                        group[FEATURES_COLS],\n",
        "                                                        group[TARGET_COL],\n",
        "                                                        test_size = 0.20,\n",
        "                                                        random_state = 42\n",
        "                                                    )\n",
        "    \n",
        "    # Get best params\n",
        "    display(HTML(f'<b>Randomized Search CV:</b>'))\n",
        "    rf = search_best_model(X_train, y_train, RandomForestRegressor(), rf_param_grid)\n",
        "    \n",
        "    display(HTML(f'<b>Best params:</b>'))\n",
        "    print(rf.best_params_)\n",
        "    \n",
        "    \n",
        "    # Training metrics\n",
        "    sat_freq_metrics['train'][f'{sat}_{freq}'] = get_metrics(np.array(y_train), rf.predict(X_train))\n",
        "\n",
        "    # Test metrics\n",
        "    sat_freq_metrics['test'][f'{sat}_{freq}'] = get_metrics(np.array(y_test), rf.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP-DGEe4rA5M"
      },
      "source": [
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "display(pd.DataFrame(sat_freq_metrics['train']))\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "display(pd.DataFrame(sat_freq_metrics['test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BYSNW2rrA5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HWOmTOMrA5O"
      },
      "source": [
        "### Other models using all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv5RPL4IrA5O"
      },
      "source": [
        "#### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQWXPG_0rA5P"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES_COLS], df[TARGET_COL], test_size = 0.20, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CMdiZVkrA5P"
      },
      "source": [
        "#### KNRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FMpjpzwrA5P"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "kn_param_grid = {\n",
        "    'n_neighbors': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'leaf_size': [30, 40, 50],\n",
        "    'p': [1,2]\n",
        "    \n",
        "}\n",
        "\n",
        "# Get best params\n",
        "display(HTML(f'<b>Randomized Search CV:</b>'))\n",
        "kn = search_best_model(X_train, y_train, KNeighborsRegressor(), knn_param_grid)\n",
        "\n",
        "display(HTML(f'<b>Best params:</b>'))\n",
        "print(knn.best_params_)\n",
        "\n",
        "\n",
        "# Get metrics\n",
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "print(get_metrics(np.array(y_train), kn.predict(X_train)))\n",
        "\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "print(get_metrics(np.array(y_test), kn.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVVTQ4RGrA5Q"
      },
      "source": [
        "#### Linear Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVCRd8dBrA5Q"
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "svr_param_grid = {\n",
        "    'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'] ,\n",
        "    'fit_intercept': [True, False],\n",
        "    'dual': [True, False],\n",
        "}\n",
        "\n",
        "\n",
        "svr = search_best_model(X_train, y_train, LinearSVR(), svr_param_grid)\n",
        "\n",
        "display(HTML(f'<b>Best params:</b>'))\n",
        "print(svr.best_params_)\n",
        "\n",
        "\n",
        "# Get metrics\n",
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "print(get_metrics(np.array(y_train), svr.predict(X_train)))\n",
        "\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "print(get_metrics(np.array(y_test), svr.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwTFbsycrA5Q"
      },
      "source": [
        "#### MLP Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqbJ4gtQrA5R"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "mlp_param_grid = {\n",
        "    'hidden_layer_sizes': [(8, 8, 64), (16, 16, 128), (32, 32, 256), (64, 64, 512)] ,\n",
        "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver': ['lbfgs', 'adam'],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'max_iter': [1000],\n",
        "}\n",
        "\n",
        "\n",
        "nn = search_best_model(X_train, y_train, MLPRegressor(), mlp_param_grid)\n",
        "\n",
        "display(HTML(f'<b>Best params:</b>'))\n",
        "print(nn.best_params_)\n",
        "\n",
        "\n",
        "# Get metrics\n",
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "print(get_metrics(np.array(y_train), nn.predict(X_train)))\n",
        "\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "print(get_metrics(np.array(y_test), nn.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSPEpwaHrA5R"
      },
      "source": [
        "#### XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4DTww2LrA5R"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [5, 10, 50, 100, 300, 1000] ,\n",
        "    'max_depth': [5, 10, 20, 50, 70, 100],\n",
        "    'objective': ['reg:linear'],\n",
        "    'booster': ['gbtree', 'gblinear', 'dart']\n",
        "}\n",
        "\n",
        "\n",
        "xgb = search_best_model(X_train, y_train, XGBRegressor(), xgb_param_grid)\n",
        "\n",
        "display(HTML(f'<b>Best params:</b>'))\n",
        "print(xgb.best_params_)\n",
        "\n",
        "\n",
        "# Get metrics\n",
        "display(HTML(f'<b>Training metrics:</b>'))\n",
        "print(get_metrics(np.array(y_train), xgb.predict(X_train)))\n",
        "\n",
        "display(HTML(f'<b>Test metrics:</b>'))\n",
        "print(get_metrics(np.array(y_test), xgb.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAOLfCfYrA5S"
      },
      "source": [
        "ax = sns.scatterplot(x=y_test, y=xgb.predict(X_test))\n",
        "ax = ax.set(xlabel = \"PM10\", ylabel=\"Prediction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtJeQ9fsrA5S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4ziDkOrA5S"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "* **RandomForestRegressor** is a good baseline model to estimate PM10\n",
        "* **XGBRegressor** is the best approach outperforming Random Forest Regressor by ~ 1 percentage point, 94.84% and 93.62% accuracy respectively"
      ]
    }
  ]
}